#!/usr/bin/env python3
"""
Enhanced Hybrid Recommendation System –¥–ª—è LoveMemory AI
–§–∞–∑–∞ 6: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Content-Based + Collaborative Filtering + Embedding-based ANN

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç:
- Content-Based —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
- Collaborative Filtering
- Embedding-based –ø–æ–∏—Å–∫ —Å Faiss
"""

import json
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import pickle
import os
import math

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–∏—Å—Ç–µ–º—ã
from content_recommender import ContentBasedRecommender, RecommendationResult
from collaborative_filtering import CollaborativeFilteringRecommender
from embedding_service import EmbeddingService

class EnhancedHybridRecommender:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≥–∏–±—Ä–∏–¥–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏"""
    
    def __init__(self, data_path: str = 'data/synthetic_v1'):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –∑–∞–≥—Ä—É–∑–∫–æ–π –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        self.data_path = data_path
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Enhanced Hybrid Recommender...")
        self.content_recommender = ContentBasedRecommender(data_path)
        self.cf_recommender = CollaborativeFilteringRecommender(data_path)
        self.embedding_service = EmbeddingService(data_path)
        
        # –í–µ—Å–∞ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ç—Ä–µ—Ö –ø–æ–¥—Ö–æ–¥–æ–≤
        self.hybrid_weights = {
            'content_weight': 0.4,
            'cf_weight': 0.3,
            'embedding_weight': 0.3
        }
        
        # –°—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
        self.content_trained = False
        self.cf_trained = False
        self.embeddings_ready = False
    
    def train_all_models(self):
        """–û–±—É—á–∞–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏ –∏ –≥–æ—Ç–æ–≤–∏—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏"""
        print("üî• –û–±—É—á–∞–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏ Enhanced Hybrid —Å–∏—Å—Ç–µ–º—ã...")
        
        # 1. Content-based –º–æ–¥–µ–ª—å (—É–∂–µ –≥–æ—Ç–æ–≤–∞)
        self.content_trained = True
        print("‚úÖ Content-based –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞")
        
        # 2. Collaborative filtering –º–æ–¥–µ–ª—å
        if self.cf_recommender.train_svd_model():
            self.cf_trained = True
            print("‚úÖ Collaborative filtering –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞")
        else:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å CF –º–æ–¥–µ–ª—å")
        
        # 3. Embedding –º–æ–¥–µ–ª—å
        if not self.embedding_service.load_embeddings():
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
            print("üß† –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏...")
            self.embedding_service.generate_user_embeddings()
            self.embedding_service.generate_product_embeddings()
            self.embedding_service.generate_pair_embeddings()
            self.embedding_service.build_faiss_indexes()
            self.embedding_service.save_embeddings()
        
        self.embeddings_ready = True
        print("‚úÖ Embedding —Å–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞")
        
        success = self.content_trained and self.cf_trained and self.embeddings_ready
        print(f"üéØ Enhanced Hybrid —Å–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞: {success}")
        return success
    
    def recommend_date_enhanced(self, pair_id: str, top_k: int = 10, 
                               user_location: Optional[Tuple[float, float]] = None) -> List[Dict]:
        """
        –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Enhanced –≥–∏–±—Ä–∏–¥–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –æ—Ç —Ç—Ä–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
        1. Content-based scoring
        2. Collaborative filtering
        3. Embedding-based ANN search
        
        Args:
            pair_id: ID –ø–∞—Ä—ã
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            user_location: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Returns:
            –°–ø–∏—Å–æ–∫ enhanced –≥–∏–±—Ä–∏–¥–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        """
        try:
            print(f"üéØ Enhanced –≥–∏–±—Ä–∏–¥–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–∞—Ä—ã: {pair_id}")
            
            # –°–æ–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –æ—Ç –≤—Å–µ—Ö —Ç—Ä–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            all_candidates = {}
            
            # 1. Content-based –∫–∞–Ω–¥–∏–¥–∞—Ç—ã
            if self.content_trained:
                content_recs = self.content_recommender.recommend_date(pair_id, top_k * 3, user_location)
                print(f"üìä Content-based: {len(content_recs)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
                
                for rec in content_recs:
                    item_id = rec.item_id
                    all_candidates[item_id] = {
                        'item_id': item_id,
                        'title': rec.title,
                        'category': rec.category,
                        'price': rec.price,
                        'location': rec.location,
                        'reasons': rec.reasons.copy(),
                        'content_score': rec.score,
                        'cf_score': 0.0,
                        'embedding_score': 0.0,
                        'final_score': 0.0
                    }
            
            # 2. Collaborative filtering –∫–∞–Ω–¥–∏–¥–∞—Ç—ã
            if self.cf_trained:
                cf_recs = self.cf_recommender.get_pair_recommendations(pair_id, top_k * 3)
                print(f"üìä Collaborative filtering: {len(cf_recs)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
                
                for rec in cf_recs:
                    item_id = rec['item_id']
                    cf_score = rec['combined_rating'] / 10.0  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 0-1
                    
                    if item_id in all_candidates:
                        all_candidates[item_id]['cf_score'] = cf_score
                        all_candidates[item_id]['reasons'].append('–ü–æ–ø—É–ª—è—Ä–Ω–æ —Å—Ä–µ–¥–∏ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ä')
                    else:
                        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–≤–∞—Ä–µ
                        product_info = self._get_product_info(item_id)
                        all_candidates[item_id] = {
                            'item_id': item_id,
                            'title': product_info.get('title', item_id),
                            'category': product_info.get('category', 'unknown'),
                            'price': product_info.get('price', 0),
                            'location': product_info.get('location'),
                            'reasons': ['–ü–æ–ø—É–ª—è—Ä–Ω–æ —Å—Ä–µ–¥–∏ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ä'],
                            'content_score': 0.0,
                            'cf_score': cf_score,
                            'embedding_score': 0.0,
                            'final_score': 0.0
                        }
            
            # 3. Embedding-based –∫–∞–Ω–¥–∏–¥–∞—Ç—ã
            if self.embeddings_ready:
                embedding_candidates = self.embedding_service.find_similar_products_ann(pair_id, top_k * 3)
                print(f"üìä Embedding ANN: {len(embedding_candidates)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
                
                for candidate in embedding_candidates:
                    item_id = candidate['item_id']
                    embedding_score = candidate['embedding_similarity']
                    
                    if item_id in all_candidates:
                        all_candidates[item_id]['embedding_score'] = embedding_score
                        all_candidates[item_id]['reasons'].append('–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –ø–æ—Ö–æ–∂ –Ω–∞ –≤–∞—à–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è')
                    else:
                        all_candidates[item_id] = {
                            'item_id': item_id,
                            'title': candidate['title'],
                            'category': candidate['category'],
                            'price': candidate['price'],
                            'location': None,
                            'reasons': ['–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –ø–æ—Ö–æ–∂ –Ω–∞ –≤–∞—à–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è'],
                            'content_score': 0.0,
                            'cf_score': 0.0,
                            'embedding_score': embedding_score,
                            'final_score': 0.0
                        }
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ scores
            for item_id, candidate in all_candidates.items():
                content_score = candidate['content_score']
                cf_score = candidate['cf_score']
                embedding_score = candidate['embedding_score']
                
                # Enhanced –≥–∏–±—Ä–∏–¥–Ω—ã–π score —Å —Ç—Ä–µ–º—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
                final_score = (
                    self.hybrid_weights['content_weight'] * content_score +
                    self.hybrid_weights['cf_weight'] * cf_score +
                    self.hybrid_weights['embedding_weight'] * embedding_score
                )
                
                candidate['final_score'] = final_score
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—é scores –≤ reasons
                score_details = f"Scores: Content={content_score:.3f}, CF={cf_score:.3f}, Emb={embedding_score:.3f}"
                candidate['reasons'].append(score_details)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º—É score
            final_recommendations = list(all_candidates.values())
            final_recommendations.sort(key=lambda x: x['final_score'], reverse=True)
            
            print(f"‚úÖ Enhanced —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {len(final_recommendations[:top_k])} —Ç–æ–ø –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
            return final_recommendations[:top_k]
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ Enhanced –≥–∏–±—Ä–∏–¥–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö: {e}")
            return []
    
    def _get_product_info(self, item_id: str) -> Dict:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–≤–∞—Ä–µ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞"""
        return self.content_recommender._get_product_info(item_id)
    
    def evaluate_enhanced_model(self, test_pairs: List[str] = None, k: int = 10) -> Dict:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç Enhanced –≥–∏–±—Ä–∏–¥–Ω—É—é –º–æ–¥–µ–ª—å"""
        print("üìä –û—Ü–µ–Ω–∏–≤–∞–µ–º Enhanced –≥–∏–±—Ä–∏–¥–Ω—É—é –º–æ–¥–µ–ª—å...")
        
        if test_pairs is None:
            test_pairs = self.content_recommender.pairs['id'].sample(min(30, len(self.content_recommender.pairs))).tolist()
        
        precision_scores = []
        recall_scores = []
        ndcg_scores = []
        diversity_scores = []
        
        for pair_id in test_pairs:
            try:
                # –ü–æ–ª—É—á–∞–µ–º Enhanced —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                recommendations = self.recommend_date_enhanced(pair_id, top_k=k)
                
                if not recommendations:
                    continue
                
                # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø–∞—Ä—ã
                pair = self.content_recommender.pairs[self.content_recommender.pairs['id'] == pair_id].iloc[0]
                user1_id = pair['user1_id']
                user2_id = pair['user2_id']
                
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è (—Ä–µ–π—Ç–∏–Ω–≥ >= 7)
                positive_interactions = self.content_recommender.interactions[
                    ((self.content_recommender.interactions['user_id'] == user1_id) | 
                     (self.content_recommender.interactions['user_id'] == user2_id)) &
                    (self.content_recommender.interactions['rating'] >= 7)
                ]
                
                relevant_items = set(positive_interactions['product_id'].tolist())
                recommended_items = set([rec['item_id'] for rec in recommendations])
                
                # Precision@k
                if len(recommended_items) > 0:
                    precision = len(relevant_items.intersection(recommended_items)) / len(recommended_items)
                    precision_scores.append(precision)
                
                # Recall@k
                if len(relevant_items) > 0:
                    recall = len(relevant_items.intersection(recommended_items)) / len(relevant_items)
                    recall_scores.append(recall)
                
                # NDCG@k
                dcg = 0.0
                for i, rec in enumerate(recommendations):
                    if rec['item_id'] in relevant_items:
                        dcg += 1.0 / math.log2(i + 2)
                
                # IDCG
                idcg = sum(1.0 / math.log2(i + 2) for i in range(min(k, len(relevant_items))))
                
                if idcg > 0:
                    ndcg = dcg / idcg
                    ndcg_scores.append(ndcg)
                
                # Diversity (—Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π)
                categories = set([rec['category'] for rec in recommendations])
                diversity = len(categories) / len(recommendations) if recommendations else 0
                diversity_scores.append(diversity)
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –ø–∞—Ä—ã {pair_id}: {e}")
                continue
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics = {
            'precision_at_k': np.mean(precision_scores) if precision_scores else 0.0,
            'recall_at_k': np.mean(recall_scores) if recall_scores else 0.0,
            'ndcg_at_k': np.mean(ndcg_scores) if ndcg_scores else 0.0,
            'diversity_at_k': np.mean(diversity_scores) if diversity_scores else 0.0,
            'num_test_pairs': len(test_pairs),
            'enhanced_weights': self.hybrid_weights,
            'all_models_ready': self.content_trained and self.cf_trained and self.embeddings_ready
        }
        
        return metrics
    
    def update_enhanced_weights(self, content_weight: float, cf_weight: float, embedding_weight: float):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –≤–µ—Å–∞ Enhanced –≥–∏–±—Ä–∏–¥–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        total_weight = content_weight + cf_weight + embedding_weight
        if abs(total_weight - 1.0) > 0.01:
            raise ValueError("–í–µ—Å–∞ –¥–æ–ª–∂–Ω—ã —Å—É–º–º–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫ 1.0")
        
        self.hybrid_weights = {
            'content_weight': content_weight,
            'cf_weight': cf_weight,
            'embedding_weight': embedding_weight
        }
        
        print(f"‚úÖ Enhanced –≤–µ—Å–∞ –æ–±–Ω–æ–≤–ª–µ–Ω—ã: Content={content_weight:.2f}, CF={cf_weight:.2f}, Embedding={embedding_weight:.2f}")
    
    def save_enhanced_model(self, model_path: str = 'models/enhanced_hybrid_v1'):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç Enhanced –≥–∏–±—Ä–∏–¥–Ω—É—é –º–æ–¥–µ–ª—å"""
        os.makedirs('models', exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        if self.cf_trained:
            self.cf_recommender.save_model(f'{model_path}_cf')
        
        if self.embeddings_ready:
            self.embedding_service.save_embeddings()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ Enhanced –º–æ–¥–µ–ª–∏
        metadata = {
            'model_id': 'enhanced_hybrid_v1',
            'type': 'enhanced_hybrid',
            'version': '1.0',
            'components': {
                'content_based': self.content_trained,
                'collaborative_filtering': self.cf_trained,
                'embedding_ann': self.embeddings_ready
            },
            'trained_on': {
                'num_users': len(self.content_recommender.users),
                'num_pairs': len(self.content_recommender.pairs),
                'num_interactions': len(self.content_recommender.interactions),
                'num_products': len(self.content_recommender.product_catalog)
            },
            'parameters': {
                'enhanced_weights': self.hybrid_weights,
                'content_weights': self.content_recommender.weights,
                'cf_n_factors': self.cf_recommender.n_factors,
                'embedding_model': self.embedding_service.model_name,
                'embedding_dim': self.embedding_service.embedding_dim
            },
            'created_at': datetime.now().isoformat()
        }
        
        with open(f'{model_path}_metadata.json', 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ Enhanced –≥–∏–±—Ä–∏–¥–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {model_path}")

def main():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã Enhanced –≥–∏–±—Ä–∏–¥–Ω–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã"""
    print("üöÄ –ó–∞–ø—É—Å–∫ Enhanced Hybrid Recommendation System")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Enhanced –≥–∏–±—Ä–∏–¥–Ω—É—é —Å–∏—Å—Ç–µ–º—É
    enhanced_recommender = EnhancedHybridRecommender()
    
    # –û–±—É—á–∞–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏
    if not enhanced_recommender.train_all_models():
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –≤—Å–µ –º–æ–¥–µ–ª–∏")
        return
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ —Å–ª—É—á–∞–π–Ω–æ–π –ø–∞—Ä–µ
    test_pair_id = enhanced_recommender.content_recommender.pairs['id'].iloc[0]
    print(f"\nüéØ –¢–µ—Å—Ç–∏—Ä—É–µ–º Enhanced —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–∞—Ä—ã: {test_pair_id}")
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    recommendations = enhanced_recommender.recommend_date_enhanced(test_pair_id, top_k=5)
    
    print(f"\nüìã –¢–æ–ø-5 Enhanced –≥–∏–±—Ä–∏–¥–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:")
    for i, rec in enumerate(recommendations, 1):
        print(f"{i}. {rec['title']}")
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {rec['category']}")
        print(f"   Final Score: {rec['final_score']:.3f}")
        print(f"   Content: {rec['content_score']:.3f} | CF: {rec['cf_score']:.3f} | Embedding: {rec['embedding_score']:.3f}")
        print(f"   –¶–µ–Ω–∞: {rec['price']:.0f} —Ä—É–±.")
        print(f"   –ü—Ä–∏—á–∏–Ω—ã: {len(rec['reasons'])} –æ–±—ä—è—Å–Ω–µ–Ω–∏–π")
        print()
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    print("üìä –û—Ü–µ–Ω–∏–≤–∞–µ–º Enhanced –º–æ–¥–µ–ª—å...")
    metrics = enhanced_recommender.evaluate_enhanced_model(k=10)
    
    print(f"\nüìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã Enhanced –≥–∏–±—Ä–∏–¥–Ω–æ–π –º–æ–¥–µ–ª–∏:")
    print(f"  Precision@10: {metrics['precision_at_k']:.3f}")
    print(f"  Recall@10: {metrics['recall_at_k']:.3f}")
    print(f"  NDCG@10: {metrics['ndcg_at_k']:.3f}")
    print(f"  Diversity@10: {metrics['diversity_at_k']:.3f}")
    print(f"  –¢–µ—Å—Ç–æ–≤—ã—Ö –ø–∞—Ä: {metrics['num_test_pairs']}")
    weights = metrics['enhanced_weights']
    print(f"  –í–µ—Å–∞: Content={weights['content_weight']:.2f}, CF={weights['cf_weight']:.2f}, Embedding={weights['embedding_weight']:.2f}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    latency_stats = enhanced_recommender.embedding_service.benchmark_search_latency(num_queries=20)
    
    print(f"\n‚è±Ô∏è –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:")
    print(f"  P95 latency: {latency_stats['p95_latency_ms']:.2f}ms")
    if latency_stats['p95_latency_ms'] > 300:
        print("  ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (P95 > 300ms)")
    else:
        print("  ‚úÖ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –Ω–æ—Ä–º–µ")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    enhanced_recommender.save_enhanced_model()
    
    print("\nüéâ Enhanced Hybrid —Å–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ production!")
    print("‚úÖ –§–∞–∑–∞ 6 (Embeddings + ANN) –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")

if __name__ == "__main__":
    main()
