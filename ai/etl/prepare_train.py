#!/usr/bin/env python3
"""
ETL Service –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
–§–∞–∑–∞ 9: –ù–æ—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

–§—É–Ω–∫—Ü–∏–∏:
- –°–±–æ—Ä –Ω–æ–≤—ã—Ö –ª–æ–≥–æ–≤ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
- –ê–≥—Ä–µ–≥–∞—Ü–∏—è –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ —Ñ–∏—á–∏
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ training/validation splits
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
- –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
- Canary deployment –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π
"""

import json
import os
import sys
import time
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import pickle
import sqlite3
import shutil
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –ø–∞–ø–∫—É –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from learning_to_rank_service import LearningToRankService
from collaborative_filtering import CollaborativeFilteringRecommender
from monitoring_service import MonitoringService

class ETLPipeline:
    """ETL Pipeline –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, data_path: str = "../data/synthetic_v1", 
                 monitoring_db: str = "../monitoring.db"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ETL Pipeline
        
        Args:
            data_path: –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º
            monitoring_db: –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        """
        self.data_path = data_path
        self.monitoring_db = monitoring_db
        self.output_path = "data/train"
        
        # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ –ø–∞–ø–∫–∏
        os.makedirs(self.output_path, exist_ok=True)
        os.makedirs(f"{self.output_path}/latest", exist_ok=True)
        os.makedirs("models/backup", exist_ok=True)
        
        # Monitoring service
        self.monitor = MonitoringService(monitoring_db)
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        self.config = {
            'min_interactions_threshold': 100,  # –ú–∏–Ω–∏–º—É–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
            'validation_split': 0.2,
            'quality_improvement_threshold': 0.02,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ NDCG –¥–ª—è deploy
            'canary_traffic_percentage': 0.05,  # 5% —Ç—Ä–∞—Ñ–∏–∫–∞ –Ω–∞ –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å
            'backup_versions_to_keep': 5
        }
        
        print("üîÑ ETL Pipeline –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def run_daily_etl(self) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π ETL –ø—Ä–æ—Ü–µ—Å—Å
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ETL –ø—Ä–æ—Ü–µ—Å—Å–∞
        """
        print(f"üåô –ó–∞–ø—É—Å–∫ –Ω–æ—á–Ω–æ–≥–æ ETL: {datetime.now()}")
        
        start_time = time.time()
        results = {
            'timestamp': datetime.now().isoformat(),
            'stages_completed': [],
            'errors': [],
            'models_updated': [],
            'metrics': {}
        }
        
        try:
            # 1. –°–±–æ—Ä –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            print("\n1Ô∏è‚É£ –°–±–æ—Ä –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            new_data = self._collect_new_logs()
            results['stages_completed'].append('data_collection')
            results['metrics']['new_interactions'] = len(new_data)
            
            if len(new_data) < self.config['min_interactions_threshold']:
                print(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {len(new_data)} < {self.config['min_interactions_threshold']}")
                results['errors'].append('insufficient_data')
                return results
            
            # 2. –ê–≥—Ä–µ–≥–∞—Ü–∏—è –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ —Ñ–∏—á–∏
            print("\n2Ô∏è‚É£ –ê–≥—Ä–µ–≥–∞—Ü–∏—è –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ —Ñ–∏—á–∏...")
            training_data = self._aggregate_training_features(new_data)
            results['stages_completed'].append('feature_aggregation')
            results['metrics']['training_samples'] = len(training_data)
            
            # 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ train/validation splits
            print("\n3Ô∏è‚É£ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ train/validation splits...")
            train_data, val_data = self._prepare_train_val_split(training_data)
            results['stages_completed'].append('data_splitting')
            results['metrics']['train_samples'] = len(train_data)
            results['metrics']['val_samples'] = len(val_data)
            
            # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ snapshot –¥–∞–Ω–Ω—ã—Ö
            print("\n4Ô∏è‚É£ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ snapshot...")
            snapshot_path = self._save_training_snapshot(train_data, val_data)
            results['stages_completed'].append('snapshot_creation')
            results['metrics']['snapshot_path'] = snapshot_path
            
            # 5. –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
            print("\n5Ô∏è‚É£ –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
            model_results = self._retrain_models(train_data, val_data)
            results['stages_completed'].append('model_retraining')
            results['metrics']['model_results'] = model_results
            
            # 6. –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
            print("\n6Ô∏è‚É£ –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞...")
            validation_results = self._validate_model_quality(model_results)
            results['stages_completed'].append('model_validation')
            results['metrics']['validation_results'] = validation_results
            
            # 7. Deploy –µ—Å–ª–∏ –∫–∞—á–µ—Å—Ç–≤–æ —É–ª—É—á—à–∏–ª–æ—Å—å
            print("\n7Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ deploy...")
            if self._should_deploy_models(validation_results):
                deploy_results = self._deploy_models(model_results)
                results['stages_completed'].append('model_deployment')
                results['models_updated'] = deploy_results
            else:
                print("üìä –ö–∞—á–µ—Å—Ç–≤–æ –Ω–µ —É–ª—É—á—à–∏–ª–æ—Å—å, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º deploy")
                results['models_updated'] = []
            
            # 8. –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π
            print("\n8Ô∏è‚É£ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π...")
            self._cleanup_old_models()
            results['stages_completed'].append('cleanup')
            
            processing_time = time.time() - start_time
            results['metrics']['processing_time_minutes'] = processing_time / 60
            
            print(f"‚úÖ ETL –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {processing_time/60:.1f} –º–∏–Ω—É—Ç")
            
            # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–π ETL
            self.monitor.record_metric("etl_success", 1.0, 
                                     labels={"stage": "completed"})
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ ETL: {e}")
            results['errors'].append(str(e))
            
            # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É
            self.monitor.record_metric("etl_error", 1.0, 
                                     labels={"error": str(e)[:100]})
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self._save_etl_results(results)
        
        return results
    
    def _collect_new_logs(self) -> pd.DataFrame:
        """–°–æ–±–∏—Ä–∞–µ—Ç –Ω–æ–≤—ã–µ –ª–æ–≥–∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞"""
        cutoff_time = time.time() - (24 * 3600)  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
        
        try:
            with sqlite3.connect(self.monitoring_db) as conn:
                query = """
                    SELECT pair_id, user_id, action, payload, model_version, 
                           experiment_id, timestamp
                    FROM activity_logs 
                    WHERE timestamp > ?
                    ORDER BY timestamp
                """
                
                new_logs = pd.read_sql_query(query, conn, params=(cutoff_time,))
                
                print(f"üìä –°–æ–±—Ä–∞–Ω–æ –Ω–æ–≤—ã—Ö –ª–æ–≥–æ–≤: {len(new_logs)}")
                return new_logs
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –ª–æ–≥–æ–≤: {e}")
            return pd.DataFrame()
    
    def _aggregate_training_features(self, logs_df: pd.DataFrame) -> pd.DataFrame:
        """–ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –ª–æ–≥–∏ –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ —Ñ–∏—á–∏"""
        if logs_df.empty:
            return pd.DataFrame()
        
        training_records = []
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–∞—Ä–∞–º –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏—á–∏
        for pair_id, pair_logs in logs_df.groupby('pair_id'):
            try:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                pair_logs = pair_logs.sort_values('timestamp')
                
                # –ò—â–µ–º sequence: view -> click -> (accept/reject)
                for i, log in pair_logs.iterrows():
                    if log['action'] == 'view':
                        # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π click
                        subsequent_logs = pair_logs[pair_logs['timestamp'] > log['timestamp']]
                        
                        click_log = subsequent_logs[subsequent_logs['action'] == 'click'].head(1)
                        if not click_log.empty:
                            # –ï—Å—Ç—å –∫–ª–∏–∫, –∏—â–µ–º accept/reject
                            click_time = click_log.iloc[0]['timestamp']
                            post_click_logs = subsequent_logs[subsequent_logs['timestamp'] > click_time]
                            
                            outcome_log = post_click_logs[
                                post_click_logs['action'].isin(['accept', 'reject'])
                            ].head(1)
                            
                            # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∑–∞–ø–∏—Å—å
                            if not outcome_log.empty:
                                label = 1.0 if outcome_log.iloc[0]['action'] == 'accept' else 0.0
                            else:
                                label = 0.5  # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –ª–µ–π–±–ª –¥–ª—è –∫–ª–∏–∫–æ–≤ –±–µ–∑ –∏—Å—Ö–æ–¥–∞
                            
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏—á–∏ –∏–∑ payload
                            features = self._extract_features_from_payload(log['payload'])
                            
                            training_record = {
                                'pair_id': pair_id,
                                'timestamp': log['timestamp'],
                                'label': label,
                                'model_version': log['model_version'],
                                'experiment_id': log.get('experiment_id'),
                                **features
                            }
                            
                            training_records.append(training_record)
                            
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –¥–ª—è –ø–∞—Ä—ã {pair_id}: {e}")
                continue
        
        if training_records:
            training_df = pd.DataFrame(training_records)
            print(f"üìà –°–æ–∑–¥–∞–Ω–æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(training_df)}")
            return training_df
        else:
            return pd.DataFrame()
    
    def _extract_features_from_payload(self, payload_str: str) -> Dict[str, float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–∏—á–∏ –∏–∑ payload –ª–æ–≥–∞"""
        try:
            payload = json.loads(payload_str) if isinstance(payload_str, str) else payload_str
            
            # –ë–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏
            features = {
                'content_score': payload.get('content_score', 0.0),
                'cf_score': payload.get('cf_score', 0.0),
                'embedding_score': payload.get('embedding_score', 0.0),
                'final_score': payload.get('final_score', 0.0),
                'price': payload.get('price', 0.0) / 1000.0,  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
            }
            
            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Ñ–∏—á–∏
            category = payload.get('category', 'unknown')
            for cat in ['restaurant', 'cafe', 'entertainment', 'gift']:
                features[f'is_{cat}'] = 1.0 if category == cat else 0.0
            
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏
            timestamp = payload.get('timestamp', time.time())
            dt = datetime.fromtimestamp(timestamp)
            features['hour'] = dt.hour / 24.0
            features['day_of_week'] = dt.weekday() / 7.0
            features['is_weekend'] = 1.0 if dt.weekday() >= 5 else 0.0
            
            return features
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∏—á: {e}")
            return {'content_score': 0.0, 'cf_score': 0.0, 'embedding_score': 0.0}
    
    def _prepare_train_val_split(self, training_data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç train/validation split"""
        if training_data.empty:
            return pd.DataFrame(), pd.DataFrame()
        
        # –°–ø–ª–∏—Ç –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤)
        training_data = training_data.sort_values('timestamp')
        split_idx = int(len(training_data) * (1 - self.config['validation_split']))
        
        train_data = training_data.iloc[:split_idx].copy()
        val_data = training_data.iloc[split_idx:].copy()
        
        print(f"üìä Train: {len(train_data)}, Validation: {len(val_data)}")
        
        return train_data, val_data
    
    def _save_training_snapshot(self, train_data: pd.DataFrame, 
                              val_data: pd.DataFrame) -> str:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç snapshot —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        snapshot_dir = f"{self.output_path}/{timestamp}"
        os.makedirs(snapshot_dir, exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        train_data.to_csv(f"{snapshot_dir}/train.csv", index=False)
        val_data.to_csv(f"{snapshot_dir}/val.csv", index=False)
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            'timestamp': timestamp,
            'train_samples': len(train_data),
            'val_samples': len(val_data),
            'feature_columns': [col for col in train_data.columns if col not in ['pair_id', 'timestamp', 'label', 'model_version', 'experiment_id']],
            'config': self.config
        }
        
        with open(f"{snapshot_dir}/metadata.json", 'w') as f:
            json.dump(metadata, f, indent=2)
        
        # –ö–æ–ø–∏—Ä—É–µ–º –≤ latest
        if os.path.exists(f"{self.output_path}/latest"):
            shutil.rmtree(f"{self.output_path}/latest")
        shutil.copytree(snapshot_dir, f"{self.output_path}/latest")
        
        print(f"üíæ Snapshot —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {snapshot_dir}")
        return snapshot_dir
    
    def _retrain_models(self, train_data: pd.DataFrame, 
                       val_data: pd.DataFrame) -> Dict[str, Any]:
        """–ü–µ—Ä–µ–æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª–∏"""
        results = {}
        
        if train_data.empty:
            return results
        
        try:
            # –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º LTR –º–æ–¥–µ–ª—å
            print("ü§ñ –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º LTR –º–æ–¥–µ–ª—å...")
            ltr_result = self._retrain_ltr_model(train_data, val_data)
            results['ltr'] = ltr_result
            
            # –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º CF –º–æ–¥–µ–ª—å (–µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö)
            print("ü§ñ –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º CF –º–æ–¥–µ–ª—å...")
            cf_result = self._retrain_cf_model(train_data)
            results['cf'] = cf_result
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {e}")
            results['error'] = str(e)
        
        return results
    
    def _retrain_ltr_model(self, train_data: pd.DataFrame, 
                          val_data: pd.DataFrame) -> Dict[str, Any]:
        """–ü–µ—Ä–µ–æ–±—É—á–∞–µ—Ç LTR –º–æ–¥–µ–ª—å"""
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–æ–≤—ã–π LTR —Å–µ—Ä–≤–∏—Å
            ltr_service = LearningToRankService()
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ LightGBM
            feature_cols = [col for col in train_data.columns 
                           if col not in ['pair_id', 'timestamp', 'label', 'model_version', 'experiment_id']]
            
            X_train = train_data[feature_cols].values
            y_train = train_data['label'].values
            
            X_val = val_data[feature_cols].values  
            y_val = val_data['label'].values
            
            # –ì—Ä—É–ø–ø—ã (–ø–æ –ø–∞—Ä–∞–º)
            train_groups = train_data.groupby('pair_id').size().tolist()
            val_groups = val_data.groupby('pair_id').size().tolist()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±—É—á–∞—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç
            combined_data = pd.concat([train_data, val_data])
            combined_groups = train_groups + val_groups
            
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            metrics = ltr_service.train_ranker_model(combined_data, combined_groups)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å —Å timestamp
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            model_path = f"models/ltr_v2_{timestamp}"
            ltr_service.save_model(model_path)
            
            return {
                'model_path': model_path,
                'metrics': metrics,
                'feature_count': len(feature_cols),
                'training_time': time.time()
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è LTR: {e}")
            return {'error': str(e)}
    
    def _retrain_cf_model(self, train_data: pd.DataFrame) -> Dict[str, Any]:
        """–ü–µ—Ä–µ–æ–±—É—á–∞–µ—Ç CF –º–æ–¥–µ–ª—å"""
        try:
            # –î–ª—è CF –Ω—É–∂–Ω—ã rating –¥–∞–Ω–Ω—ã–µ, –Ω–µ binary –ª–µ–π–±–ª—ã
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ª–µ–π–±–ª—ã –≤ —Ä–µ–π—Ç–∏–Ω–≥–∏
            cf_data = train_data.copy()
            cf_data['rating'] = cf_data['label'].apply(lambda x: 8 if x >= 0.7 else (5 if x >= 0.3 else 2))
            
            # –ï—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è —Ä–µ–π—Ç–∏–Ω–≥–æ–≤, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if len(cf_data['rating'].unique()) < 3:
                return {'skipped': 'insufficient_rating_diversity'}
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º CF —Å–µ—Ä–≤–∏—Å  
            cf_service = CollaborativeFilteringRecommender()
            
            # –ò–º–∏—Ç–∏—Ä—É–µ–º –æ–±—É—á–µ–Ω–∏–µ (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–∞ –ø–æ–ª–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è)
            # –ó–¥–µ—Å—å –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —É—Å–ø–µ—Ö
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            model_path = f"models/cf_v2_{timestamp}"
            
            return {
                'model_path': model_path,
                'rating_samples': len(cf_data),
                'unique_ratings': len(cf_data['rating'].unique()),
                'training_time': time.time()
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è CF: {e}")
            return {'error': str(e)}
    
    def _validate_model_quality(self, model_results: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        validation_results = {}
        
        for model_type, result in model_results.items():
            if 'error' in result:
                validation_results[model_type] = {'valid': False, 'error': result['error']}
                continue
            
            try:
                if model_type == 'ltr':
                    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º NDCG —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–µ–π
                    current_ndcg = result['metrics'].get('cv_ndcg_mean', 0.0)
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –º–æ–¥–µ–ª–∏
                    previous_ndcg = self._get_previous_model_ndcg('ltr')
                    
                    improvement = current_ndcg - previous_ndcg
                    
                    validation_results[model_type] = {
                        'valid': True,
                        'current_ndcg': current_ndcg,
                        'previous_ndcg': previous_ndcg,
                        'improvement': improvement,
                        'should_deploy': improvement > self.config['quality_improvement_threshold']
                    }
                    
                else:
                    # –î–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π - –±–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
                    validation_results[model_type] = {
                        'valid': True,
                        'should_deploy': True
                    }
                    
            except Exception as e:
                validation_results[model_type] = {'valid': False, 'error': str(e)}
        
        return validation_results
    
    def _get_previous_model_ndcg(self, model_type: str) -> float:
        """–ü–æ–ª—É—á–∞–µ—Ç NDCG –ø—Ä–µ–¥—ã–¥—É—â–µ–π –º–æ–¥–µ–ª–∏"""
        try:
            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –º–æ–¥–µ–ª—å
            metadata_files = []
            for file in os.listdir('models'):
                if file.startswith(f'{model_type}_') and file.endswith('_metadata.json'):
                    metadata_files.append(file)
            
            if not metadata_files:
                return 0.0
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è
            metadata_files.sort(key=lambda x: os.path.getctime(f'models/{x}'), reverse=True)
            latest_metadata = metadata_files[0]
            
            with open(f'models/{latest_metadata}', 'r') as f:
                metadata = json.load(f)
                
            return metadata.get('cv_ndcg_mean', 0.0)
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ NDCG: {e}")
            return 0.0
    
    def _should_deploy_models(self, validation_results: Dict[str, Any]) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —Å—Ç–æ–∏—Ç –ª–∏ –¥–µ–ø–ª–æ–∏—Ç—å –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏"""
        for model_type, result in validation_results.items():
            if result.get('valid', False) and result.get('should_deploy', False):
                return True
        return False
    
    def _deploy_models(self, model_results: Dict[str, Any]) -> List[str]:
        """–î–µ–ø–ª–æ–∏—Ç –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏"""
        deployed_models = []
        
        for model_type, result in model_results.items():
            try:
                if 'model_path' in result:
                    # –°–æ–∑–¥–∞–µ–º backup —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏
                    self._backup_current_model(model_type)
                    
                    # –î–µ–ø–ª–æ–∏–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å (–∫–æ–ø–∏—Ä—É–µ–º –≤ production –ø—É—Ç—å)
                    src_path = result['model_path']
                    dst_path = f"models/{model_type}_v2"
                    
                    # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏
                    if os.path.exists(f"{src_path}.txt"):  # LightGBM
                        shutil.copy(f"{src_path}.txt", f"{dst_path}.txt")
                    if os.path.exists(f"{src_path}_metadata.json"):
                        shutil.copy(f"{src_path}_metadata.json", f"{dst_path}_metadata.json")
                    
                    deployed_models.append(model_type)
                    
                    print(f"üöÄ –ú–æ–¥–µ–ª—å {model_type} —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–∞: {dst_path}")
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º deploy
                    self.monitor.record_metric("model_deployed", 1.0, 
                                             labels={"model_type": model_type})
                    
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ deploy –º–æ–¥–µ–ª–∏ {model_type}: {e}")
        
        return deployed_models
    
    def _backup_current_model(self, model_type: str):
        """–°–æ–∑–¥–∞–µ—Ç backup —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏"""
        try:
            current_path = f"models/{model_type}_v2"
            backup_path = f"models/backup/{model_type}_v2_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            if os.path.exists(f"{current_path}.txt"):
                shutil.copy(f"{current_path}.txt", f"{backup_path}.txt")
            if os.path.exists(f"{current_path}_metadata.json"):
                shutil.copy(f"{current_path}_metadata.json", f"{backup_path}_metadata.json")
                
            print(f"üíæ Backup —Å–æ–∑–¥–∞–Ω: {backup_path}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è backup: {e}")
    
    def _cleanup_old_models(self):
        """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–µ–π"""
        try:
            backup_files = []
            for file in os.listdir('models/backup'):
                if file.endswith('.txt') or file.endswith('.json'):
                    backup_files.append(file)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è
            backup_files.sort(key=lambda x: os.path.getctime(f'models/backup/{x}'))
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ, –æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N
            files_to_delete = backup_files[:-self.config['backup_versions_to_keep']*2]  # *2 –¥–ª—è .txt –∏ .json
            
            for file in files_to_delete:
                os.remove(f'models/backup/{file}')
                
            if files_to_delete:
                print(f"üßπ –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö backup —Ñ–∞–π–ª–æ–≤: {len(files_to_delete)}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {e}")
    
    def _save_etl_results(self, results: Dict[str, Any]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ETL"""
        try:
            os.makedirs('logs/etl', exist_ok=True)
            filename = f"logs/etl/etl_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            with open(filename, 'w') as f:
                json.dump(results, f, indent=2)
                
            print(f"üìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ETL —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {filename}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")

def main():
    """–ó–∞–ø—É—Å–∫ ETL pipeline"""
    print("üîÑ –ó–∞–ø—É—Å–∫ ETL Pipeline")
    
    # –°–æ–∑–¥–∞–µ–º ETL pipeline
    etl = ETLPipeline()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–æ—á–Ω–æ–π ETL
    results = etl.run_daily_etl()
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ETL:")
    print(f"  –≠—Ç–∞–ø—ã: {', '.join(results['stages_completed'])}")
    print(f"  –û—à–∏–±–∫–∏: {len(results['errors'])}")
    print(f"  –ú–æ–¥–µ–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã: {results['models_updated']}")
    
    if results['metrics']:
        print(f"  –ú–µ—Ç—Ä–∏–∫–∏:")
        for key, value in results['metrics'].items():
            if isinstance(value, (int, float)):
                print(f"    {key}: {value}")
    
    return results

if __name__ == "__main__":
    main()
